{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxYFrtX/TFvhJ3E52Ljv/e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CkSkY3j17xEf","executionInfo":{"status":"error","timestamp":1681626453136,"user_tz":-330,"elapsed":6839,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}},"outputId":"aaa5a80b-fe95-455c-a999-1680c7eb2538","colab":{"base_uri":"https://localhost:8080/","height":374}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-66321358d000>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhiddenlayer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hiddenlayer'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","from IPython.display import clear_output\n","from torch import nn\n","import hiddenlayer as hl\n","from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader, sampler\n","from PIL import Image\n","import torch\n","import matplotlib.pyplot as plt\n","import time"]},{"cell_type":"code","source":["if not os.path.exists(\"pytorch_unet.py\"):\n","    if not os.path.exists(\"pytorch_unet\"):\n","        !git clone https://github.com/usuyama/pytorch-unet.git\n","\n","    # %cd pytorch-unet"],"metadata":{"id":"QtCDtZa97_P7","executionInfo":{"status":"aborted","timestamp":1681626453137,"user_tz":-330,"elapsed":10,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check torch\n","import torch\n","\n","if not torch.cuda.is_available():\n","  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n","\n","print(\"device name\", torch.cuda.get_device_name(0))"],"metadata":{"id":"gEKYRwMv7_UF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls -l"],"metadata":{"id":"wPN5KYnf7_XX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reference to https://www.kaggle.com/cordmaur/38-cloud-simple-unet\n","\n","class CloudDataset(Dataset):\n","    def __init__(self, r_dir, g_dir, b_dir, nir_dir, gt_dir, pytorch=True):\n","        super().__init__()\n","        \n","        # Loop through the files in red folder and combine, into a dictionary, the other bands\n","        self.files = [self.combine_files(f, g_dir, b_dir, nir_dir, gt_dir) for f in r_dir.iterdir() if not f.is_dir()]\n","        self.pytorch = pytorch\n","        \n","    def combine_files(self, r_file: Path, g_dir, b_dir,nir_dir, gt_dir):\n","        \n","        files = {'red': r_file, \n","                 'green':g_dir/r_file.name.replace('red', 'green'),\n","                 'blue': b_dir/r_file.name.replace('red', 'blue'), \n","                 'nir': nir_dir/r_file.name.replace('red', 'nir'),\n","                 'gt': gt_dir/r_file.name.replace('red', 'gt')}\n","\n","        return files\n","                                       \n","    def __len__(self):\n","        \n","        return len(self.files)\n","     \n","    def open_as_array(self, idx, invert=False, include_nir=False):\n","\n","        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n","                            np.array(Image.open(self.files[idx]['green'])),\n","                            np.array(Image.open(self.files[idx]['blue'])),\n","                           ], axis=2)\n","    \n","        if include_nir:\n","            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n","            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n","    \n","        if invert:\n","            raw_rgb = raw_rgb.transpose((2,0,1))\n","    \n","        # normalize\n","        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n","    \n","\n","    def open_mask(self, idx, add_dims=False):\n","        \n","        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n","        raw_mask = np.where(raw_mask==255, 1, 0)\n","        \n","        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n","    \n","    def __getitem__(self, idx):\n","        \n","        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n","        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n","        \n","        return x, y"],"metadata":{"id":"v_Ma9fqP7_cG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create torch dataset like defined in CloudDataset class\n","base_path = Path('../input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training')\n","data = CloudDataset(base_path/'train_red', \n","                    base_path/'train_green', \n","                    base_path/'train_blue', \n","                    base_path/'train_nir',\n","                    base_path/'train_gt')\n","len(data)"],"metadata":{"id":"9eHnaOJi7_jK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# returns features x and target feature y\n","x, y = data[1000]\n","x.shape, y.shape"],"metadata":{"id":"oo6MUYSf7_pL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize raw image and ground truth\n","image_index = 800\n","\n","fig, ax = plt.subplots(1,2, figsize=(10,9))\n","ax[0].imshow(data.open_as_array(image_index))\n","ax[1].imshow(data.open_mask(image_index))\n","\n","# left -> raw image\n","# right Ground-Truth Mask (as binary image)"],"metadata":{"id":"diD-uCef7_tK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset, valid_dataset = torch.utils.data.random_split(data, (6000, 2400))"],"metadata":{"id":"x1hie6aT7_wl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create dataloads sample from dataset\n","\n","train_dataload = DataLoader(train_dataset, batch_size=3, shuffle=True)\n","valid_dataload = DataLoader(valid_dataset, batch_size=3, shuffle=True)"],"metadata":{"id":"Tlww2ASe7_zU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test dataload\n","xb, yb = next(iter(train_dataload))\n","xb.shape, yb.shape"],"metadata":{"id":"0F24jP5r7_2W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class UNET(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","\n","        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n","        self.conv2 = self.contract_block(32, 64, 3, 1)\n","        self.conv3 = self.contract_block(64, 128, 3, 1)\n","\n","        self.upconv3 = self.expand_block(128, 64, 3, 1)\n","        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n","        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n","\n","    def __call__(self, x):\n","\n","        # downsampling part\n","        conv1 = self.conv1(x)\n","        conv2 = self.conv2(conv1)\n","        conv3 = self.conv3(conv2)\n","\n","        upconv3 = self.upconv3(conv3)\n","\n","        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n","        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n","\n","        return upconv1\n","\n","    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n","\n","        contract = nn.Sequential(\n","            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n","            torch.nn.BatchNorm2d(out_channels),\n","            torch.nn.ReLU(),\n","            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n","            torch.nn.BatchNorm2d(out_channels),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","                                 )\n","\n","        return contract\n","\n","    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n","\n","        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n","                            torch.nn.BatchNorm2d(out_channels),\n","                            torch.nn.ReLU(),\n","                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n","                            torch.nn.BatchNorm2d(out_channels),\n","                            torch.nn.ReLU(),\n","                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n","                            )\n","        return expand"],"metadata":{"id":"d5OXq9G38AQG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install hiddenlayer"],"metadata":{"id":"t8xkmsKI8AUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["unet = UNET(4,2)"],"metadata":{"id":"HQiuyvY_8AYe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n","\n","graph = hl.build_graph(unet, torch.zeros([12, 4, 384, 384]), transforms=transforms)\n","graph.theme = hl.graph.THEMES['blue'].copy()\n","graph.save('rnn_hiddenlayer', format='png')"],"metadata":{"id":"Vv3-SmUy8kUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing one pass\n","xb, yb = next(iter(train_dataload))\n","xb.shape, yb.shape\n","\n","pred = unet(xb)\n","pred.shape"],"metadata":{"id":"JvFtHYbm8kXp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=1):\n","    start = time.time()\n","    model.cuda()\n","\n","    train_loss, valid_loss = [], []\n","\n","    best_acc = 0.0\n","\n","    for epoch in range(epochs):\n","        print('Epoch {}/{}'.format(epoch, epochs - 1))\n","        print('-' * 10)\n","\n","        for phase in ['train', 'valid']:\n","            if phase == 'train':\n","                model.train(True)  # Set trainind mode = true\n","                dataloader = train_dataload\n","            else:\n","                model.train(False)  # Set model to evaluate mode\n","                dataloader = valid_dataload\n","\n","            running_loss = 0.0\n","            running_acc = 0.0\n","\n","            step = 0\n","\n","            # iterate over data\n","            for x, y in dataloader:\n","                x = x.cuda()\n","                y = y.cuda()\n","                step += 1\n","\n","                # forward pass\n","                if phase == 'train':\n","                    # zero the gradients\n","                    optimizer.zero_grad()\n","                    outputs = model(x)\n","                    loss = loss_fn(outputs, y)\n","\n","                    # the backward pass frees the graph memory, so there is no \n","                    # need for torch.no_grad in this training pass\n","                    loss.backward()\n","                    optimizer.step()\n","                    # scheduler.step()\n","\n","                else:\n","                    with torch.no_grad():\n","                        outputs = model(x)\n","                        loss = loss_fn(outputs, y.long())\n","\n","                # stats - whatever is the phase\n","                acc = acc_fn(outputs, y)\n","\n","                running_acc  += acc*dataloader.batch_size\n","                running_loss += loss*dataloader.batch_size \n","\n","                if step % 100 == 0:\n","                    # clear_output(wait=True)\n","                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n","                    # print(torch.cuda.memory_summary())\n","\n","            epoch_loss = running_loss / len(dataloader.dataset)\n","            epoch_acc = running_acc / len(dataloader.dataset)\n","\n","            clear_output(wait=True)\n","            print('Epoch {}/{}'.format(epoch, epochs - 1))\n","            print('-' * 10)\n","            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n","            print('-' * 10)\n","\n","            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n","\n","    time_elapsed = time.time() - start\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n","    \n","    return train_loss, valid_loss    \n","\n","def acc_metric(predb, yb):\n","    return (predb.argmax(dim=1) == yb.cuda()).float().mean()"],"metadata":{"id":"SA8LUmZG8kbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss() # choose loss function\n","opt = torch.optim.Adam(unet.parameters(), lr=0.01) # choose gradient function\n","\n","# start training\n","train_loss, valid_loss = train(unet, train_dataload, valid_dataload, loss_fn, opt, acc_metric, epochs=2)"],"metadata":{"id":"j5Fjbadg8kd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loss\n","valid_loss"],"metadata":{"id":"UiWmF-hY8kgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize Result\n","plt.figure(figsize=(10,8))\n","plt.plot(train_loss, label='Train loss')\n","plt.plot(valid_loss, label='Valid loss')\n","plt.legend()"],"metadata":{"id":"5UNiOVwE8kj2"},"execution_count":null,"outputs":[]}]}