{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13myfRwdymFXWm3BjPM4GhctmiuVtH9F6","authorship_tag":"ABX9TyO9qF+li5fDOgfjkpzNTcNt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t0eRteAmeh7n"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","from pathlib import Path\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from tensorflow.keras import layers\n","from keras.utils import Sequence\n","from tensorflow.keras.models import Model\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import time\n","#from tensorflow.keras.layers.experimental.preprocessing import ToTensor\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler"]},{"cell_type":"code","source":["import numpy as np\n","train, val = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n","\n","print(\"Train data is: \", train[:5], \"\\n\\n\", \"Length of train data is: \", len(train), \"\\n\")\n","print(\"Train data is: \", dev[:5], \"\\n\\n\", \"Length of train data is: \", len(dev), \"\\n\")\n","\n","\n","\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80, random_state=42)\n","\n","\n","#pip install splitfolders\n","import splitfolders\n","\n","image_directory= r'C:\\Users\\ugoch\\Desktop\\16 OBU students_Model\\CNN from scratch\\data_mv'\n","splitfolders.ratio(image_directory, output=\"output\",\n","        seed=42, ratio=(0.7, 0.15, 0.15), group_prefix=None, move=False) # default values\n"],"metadata":{"id":"5C-Bg0cfeJOe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_red_dir='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_red'\n","train_green_dir='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_green'\n","train_blue_dir='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_blue'\n","train_nir_dir='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_nir'\n","train_gt_dir='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_gt'\n","\n","val_red_dir ='/content/drive/MyDrive/DATA_SET_1/Train_/Val_rgb_nir/val_red'\n","val_green_dir = '/content/drive/MyDrive/DATA_SET_1/Train_/Val_rgb_nir/val_green'\n","val_blue_dir = '/content/drive/MyDrive/DATA_SET_1/Train_/Val_rgb_nir/val_blue'\n","val_nir_dir = '/content/drive/MyDrive/DATA_SET_1/Train_/Val_rgb_nir/val_nir'\n","val_gt_dir = '/content/drive/MyDrive/DATA_SET_1/Train_/Val_gt'\n","\n","test_red_dir ='/content/drive/MyDrive/DATA_SET_1/Test_/Test_rgb_nir/test_red'\n","test_green_dir = '/content/drive/MyDrive/DATA_SET_1/Test_/Test_rgb_nir/test_green'\n","test_blue_dir = '/content/drive/MyDrive/DATA_SET_1/Test_/Test_rgb_nir/test_blue'\n","test_nir_dir = '/content/drive/MyDrive/DATA_SET_1/Test_/Test_rgb_nir/test_nir'\n","\n","user_batch_size = 1"],"metadata":{"id":"y0Q8_ASxdY6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TrainDataGenerator(Sequence):\n","    def __init__(self, base_path, red_dir, green_dir, blue_dir, nir_dir, gt_dir, batch_size):\n","        self.base_path = base_path\n","        self.batch_size = batch_size\n","        self.red_dir = red_dir\n","        self.green_dir =  green_dir\n","        self.blue_dir =  blue_dir\n","        self.nir_dir = nir_dir\n","        self.gt_dir = gt_dir\n","        \n","        self.file_names = os.listdir(self.red_dir)\n","        self.file_names = [ '_'.join(i.split('_')[1:]) for i in self.file_names]\n","        self.num_samples = len(self.file_names)\n","\n","    def __len__(self):\n","        return int(np.ceil(self.num_samples / float(self.batch_size)))\n","\n","    def preprocess_image(self, red_img, green_img, blue_img, nir_img, gt_img):\n","        transforms = tf.keras.Sequential([\n","            tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255),\n","            #tf.keras.layers.experimental.preprocessing.ToTensor()\n","        ])\n","\n","        red = transforms(red_img)\n","        green = transforms(green_img)\n","        blue = transforms(blue_img)\n","        nir = transforms(nir_img)\n","        gt = transforms(gt_img)\n","\n","        return red, green, blue, nir, gt\n","\n","    def __getitem__(self, idx):\n","        batch_files = self.file_names[idx*self.batch_size:(idx+1)*self.batch_size]\n","        batch_x = []\n","        batch_y = []\n","        for file_name in batch_files:\n","            #print(self.red_dir / 'red_' + file_name)\n","            red_img = np.array(Image.open(os.path.join(self.red_dir, 'red_' + file_name)))\n","            green_img = np.array(Image.open(os.path.join(self.green_dir, 'green_' + file_name)))\n","            blue_img = np.array(Image.open(os.path.join(self.blue_dir, 'blue_' + file_name)))\n","            nir_img = np.array(Image.open(os.path.join(self.nir_dir, 'nir_' + file_name)))\n","            gt_img = np.array(Image.open(os.path.join(self.gt_dir, 'gt_' + file_name)))\n","\n","            #Preprocessing\n","            red, green, blue, nir, gt = self.preprocess_image(red_img, green_img, blue_img, nir_img, gt_img)\n","            x = np.stack([red, green, blue, nir], axis=-1)\n","            y = gt\n","            batch_x.append(x)\n","            batch_y.append(y)\n","       \n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","        return batch_x, batch_y\n"],"metadata":{"id":"7F0hWmA6efMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = TrainDataGenerator(base_path='/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir', red_dir = train_red_dir, green_dir = train_green_dir, blue_dir = train_blue_dir, nir_dir = train_nir_dir, gt_dir = train_gt_dir, batch_size=user_batch_size)\n","val_data = TrainDataGenerator(base_path='/content/drive/MyDrive/DATA_SET_1/Train_/Val_rgb_nir', red_dir = val_red_dir, green_dir = val_green_dir, blue_dir = val_blue_dir, nir_dir = val_nir_dir, gt_dir = val_gt_dir, batch_size=user_batch_size)\n","\n","print(len(train_data))\n","print(len(val_data))\n","print(train_data.num_samples)\n","print(val_data.num_samples)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZHGgpNMq6do","executionInfo":{"status":"ok","timestamp":1681811765252,"user_tz":-330,"elapsed":1759,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}},"outputId":"aac3bf04-827f-4157-a66d-2796d8a7b303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6000\n","2400\n","6000\n","2400\n"]}]},{"cell_type":"code","source":["class TestDataGenerator(Sequence):\n","    def __init__(self, base_path, red_dir, green_dir, blue_dir, nir_dir, batch_size):\n","        self.base_path = base_path\n","        self.batch_size = batch_size\n","        self.red_dir = red_dir\n","        self.green_dir =  green_dir\n","        self.blue_dir =  blue_dir\n","        self.nir_dir = nir_dir\n","        \n","        self.file_names = os.listdir(self.red_dir)\n","        self.file_names = [ '_'.join(i.split('_')[1:]) for i in self.file_names]\n","        self.num_samples = len(self.file_names)\n","\n","    def __len__(self):\n","        return int(np.ceil(self.num_samples / float(self.batch_size)))\n","\n","    def preprocess_image(self, red_img, green_img, blue_img, nir_img, gt_img):\n","        transforms = tf.keras.Sequential([\n","            tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255),\n","            #tf.keras.layers.experimental.preprocessing.ToTensor()\n","        ])\n","\n","        red = transforms(red_img)\n","        green = transforms(green_img)\n","        blue = transforms(blue_img)\n","        nir = transforms(nir_img)\n","\n","        return red, green, blue, nir\n","\n","    def __getitem__(self, idx):\n","        batch_files = self.file_names[idx*self.batch_size:(idx+1)*self.batch_size]\n","        batch_x = []\n","        batch_y = []\n","        for file_name in batch_files:\n","            red_img = np.array(Image.open(self.red_dir / 'red_' + file_name))\n","            green_img = np.array(Image.open(self.green_dir / 'green_' + file_name))\n","            blue_img = np.array(Image.open(self.blue_dir / 'blue_' + file_name))\n","            nir_img = np.array(Image.open(self.nir_dir / 'nir_' + file_name))\n","            gt_img = np.array(Image.open(self.gt_dir / 'gt_' + file_name))\n","\n","            #Preprocessing\n","            red, green, blue, nir, gt = self.preprocess_image(red_img, green_img, blue_img, nir_img, gt_img)\n","            x = np.stack([red, green, blue, nir], axis=-1)\n","            y = gt\n","            batch_x.append(x)\n","            batch_y.append(y)\n","       \n","        batch_x = np.array(batch_x)\n","        batch_y = np.array(batch_y)\n","        return batch_x, batch_y\n"],"metadata":{"id":"LP1HWFVQlyWS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data =  TestDataGenerator(base_path='/content/drive/MyDrive/DATA_SET_1/Train_/Test_rgb_nir', red_dir = test_red_dir, green_dir = test_green_dir, blue_dir = test_blue_dir, nir_dir = test_nir_dir, batch_size=user_batch_size)\n","print(len(test_data))\n","print(test_data.num_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4XXAepD1mFff","executionInfo":{"status":"ok","timestamp":1681811773185,"user_tz":-330,"elapsed":2852,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}},"outputId":"aafd7acf-ebc5-4166-ebbd-f8e6af15dc8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9201\n","9201\n"]}]},{"cell_type":"code","source":["def double_conv(inputs, filters, kernel_size=3, padding='same', activation='relu'):\n","    conv = Conv2D(filters, kernel_size, padding=padding, activation=activation)(inputs)\n","    conv = Conv2D(filters, kernel_size, padding=padding, activation=activation)(conv)\n","    return conv\n","\n","def UNET(in_channels, out_channels):\n","    inputs = tf.keras.layers.Input(shape=(None, None, in_channels))\n","\n","    # Contracting path\n","    conv1 = double_conv(inputs, 64)\n","    pool1 = MaxPooling2D(pool_size=2)(conv1)\n","    conv2 = double_conv(pool1, 128)\n","    pool2 = MaxPooling2D(pool_size=2)(conv2)\n","    conv3 = double_conv(pool2, 256)\n","    pool3 = MaxPooling2D(pool_size=2)(conv3)\n","    conv4 = double_conv(pool3, 512)\n","    pool4 = MaxPooling2D(pool_size=2)(conv4)\n","    conv5 = double_conv(pool4, 1024)\n","\n","    # Expanding path\n","    upconv4 = UpSampling2D(size=2)(conv5)\n","    concat4 = Concatenate()([conv4, upconv4])\n","    upconv3 = UpSampling2D(size=2)(concat4)\n","    concat3 = Concatenate()([conv3, upconv3])\n","    upconv2 = UpSampling2D(size=2)(concat3)\n","    concat2 = Concatenate()([conv2, upconv2])\n","    upconv1 = UpSampling2D(size=2)(concat2)\n","    concat1 = Concatenate()([conv1, upconv1])\n","    outputs = Conv2D(out_channels, kernel_size=1, padding='same', activation='sigmoid')(concat1)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","\n","\n","def jacard_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n","\n","def jacard_coef_loss(y_true, y_pred):\n","    return -jacard_coef(y_true, y_pred)\n","\n","model = UNET(4, 1)\n","model.summary()\n","model.compile(optimizer='adam', loss = [jacard_coef_loss], metrics=[jacard_coef])"],"metadata":{"id":"TVt07GFZp3Gs","executionInfo":{"status":"ok","timestamp":1681811779844,"user_tz":-330,"elapsed":3557,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"450142c5-060e-4845-b0dd-510d12479f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None, None,  0           []                               \n","                                 4)]                                                              \n","                                                                                                  \n"," conv2d (Conv2D)                (None, None, None,   2368        ['input_1[0][0]']                \n","                                64)                                                               \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, None, None,   36928       ['conv2d[0][0]']                 \n","                                64)                                                               \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['conv2d_1[0][0]']               \n","                                64)                                                               \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, None, None,   73856       ['max_pooling2d[0][0]']          \n","                                128)                                                              \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, None, None,   147584      ['conv2d_2[0][0]']               \n","                                128)                                                              \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['conv2d_3[0][0]']               \n","                                128)                                                              \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, None, None,   295168      ['max_pooling2d_1[0][0]']        \n","                                256)                                                              \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, None, None,   590080      ['conv2d_4[0][0]']               \n","                                256)                                                              \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['conv2d_5[0][0]']               \n","                                256)                                                              \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, None, None,   1180160     ['max_pooling2d_2[0][0]']        \n","                                512)                                                              \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, None, None,   2359808     ['conv2d_6[0][0]']               \n","                                512)                                                              \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['conv2d_7[0][0]']               \n","                                512)                                                              \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, None, None,   4719616     ['max_pooling2d_3[0][0]']        \n","                                1024)                                                             \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, None, None,   9438208     ['conv2d_8[0][0]']               \n","                                1024)                                                             \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, None, None,   0           ['conv2d_9[0][0]']               \n","                                1024)                                                             \n","                                                                                                  \n"," concatenate (Concatenate)      (None, None, None,   0           ['conv2d_7[0][0]',               \n","                                1536)                             'up_sampling2d[0][0]']          \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, None, None,   0          ['concatenate[0][0]']            \n","                                1536)                                                             \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, None, None,   0           ['conv2d_5[0][0]',               \n","                                1792)                             'up_sampling2d_1[0][0]']        \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, None, None,   0          ['concatenate_1[0][0]']          \n","                                1792)                                                             \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, None, None,   0           ['conv2d_3[0][0]',               \n","                                1920)                             'up_sampling2d_2[0][0]']        \n","                                                                                                  \n"," up_sampling2d_3 (UpSampling2D)  (None, None, None,   0          ['concatenate_2[0][0]']          \n","                                1920)                                                             \n","                                                                                                  \n"," concatenate_3 (Concatenate)    (None, None, None,   0           ['conv2d_1[0][0]',               \n","                                1984)                             'up_sampling2d_3[0][0]']        \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, None, None,   1985        ['concatenate_3[0][0]']          \n","                                1)                                                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 18,845,761\n","Trainable params: 18,845,761\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#Callbacks\n","def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","def getCallbacks(numEpochs):\n","    exponential_decay_fn = exponential_decay(0.0001, numEpochs)\n","    \n","    lr_scheduler = LearningRateScheduler(\n","        exponential_decay_fn, #function\n","        verbose=1\n","    )\n","    \n","    checkpoint = ModelCheckpoint(\n","        filepath = os.path.join('{}.h5'.format('UNET')),\n","        save_best_only = True,\n","    #     save_weights_only = False,\n","        monitor = 'val_loss',\n","        mode = 'auto',\n","        verbose = 1\n","    )\n","    \n","    earlystop = EarlyStopping(\n","        monitor = 'val_loss',\n","        min_delta = 0.001,\n","        patience = 6,\n","        mode = 'auto',\n","        verbose = 1,\n","        restore_best_weights = True\n","    )\n","  \n","    callbacks = [checkpoint, earlystop, lr_scheduler]\n","\n","    return callbacks"],"metadata":{"id":"OvxxtFC7vDU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" numEpochs = 10\n"," history = model.fit(\n","        train_data,\n","        # steps_per_epoch=np.ceil(len(os.listdir(dir_struct_dict['train_images']))/user_batch_size),\n","        validation_data = val_data,\n","        batch_size=user_batch_size,\n","        # validation_steps = np.ceil(len(os.listdir(dir_struct_dict['val_images']))/user_batch_size),\n","        epochs = numEpochs,\n","        callbacks=getCallbacks(numEpochs),\n","        use_multiprocessing=False,\n","        verbose=1\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"RWPBmIz_PoHb","executionInfo":{"status":"error","timestamp":1681812596418,"user_tz":-330,"elapsed":676,"user":{"displayName":"Dhairya Trivedi","userId":"04147883333754707565"}},"outputId":"c9241a6a-67ec-4217-fdb9-77c1203f4d47"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-5b067040830d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnumEpochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;31m# steps_per_epoch=np.ceil(len(os.listdir(dir_struct_dict['train_images']))/user_batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-0c8c51985b4d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mblue_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblue_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blue_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mnir_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnir_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nir_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mgt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#Preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DATA_SET_1/Train_/Train_rgb_nir/train_gt/gt_patch_413_20_by_14_LC08_L1TP_047023_20160920_20170221_01_T1.TIF'"]}]},{"cell_type":"code","source":["\"\"\"# Parameters\n","params = {'dim': (32,32,32),\n","          'batch_size': 32,\n","          'n_classes': 6,\n","          'n_channels': 1,\n","          'shuffle': True}\n","\n","# Datasets\n","partition = # IDs\n","labels = # Labels\n","\n","# Generators\n","training_generator = DataGenerator(partition['train'], labels, **params)\n","validation_generator = DataGenerator(partition['validation'], labels, **params)\n","\n","# Design model\n","model = Sequential()\n","[...] # Architecture\n","model.compile()\n","\n","# Train model on dataset\n","model.fit_generator(generator=training_generator,\n","                    validation_data=validation_generator,\n","                    use_multiprocessing=True,\n","                    workers=6)\n","\n","\n","Model.fit(\n","    x=None,\n","    y=None,\n","    batch_size=None,\n","    epochs=1,\n","    verbose=\"auto\",\n","    callbacks=None,\n","    validation_split=0.0,\n","    validation_data=None,\n","    shuffle=True,\n","    class_weight=None,\n","    sample_weight=None,\n","    initial_epoch=0,\n","    steps_per_epoch=None,\n","    validation_steps=None,\n","    validation_batch_size=None,\n","    validation_freq=1,\n","    max_queue_size=10,\n","    workers=1,\n","    use_multiprocessing=False,\n",")\"\"\""],"metadata":{"id":"TkVcJRxdEDkH"},"execution_count":null,"outputs":[]}]}